{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdb0700f",
   "metadata": {},
   "source": [
    "# Multiple Choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35e8560e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mFetching repo metadata...\u001b[0m\n",
      "\u001b[1;33mGenerating file list...\u001b[0m\n",
      "\u001b[1;33m[Warning] jq not installed, using grep/awk for metadata json parsing (slower). Consider installing jq for better parsing performance.\u001b[0m\n",
      "\u001b[1;33mStarting download with aria2c to ./...\n",
      "\u001b[0m\n",
      "Download Results:\n",
      "gid   |stat|avg speed  |path/URI\n",
      "======+====+===========+=======================================================\n",
      "2ec64d|\u001b[1;32mOK\u001b[0m  |       0B/s|c3/test-00000-of-00001.parquet\n",
      "a2a20d|\u001b[1;32mOK\u001b[0m  |       0B/s|c3/validation-00000-of-00001.parquet\n",
      "d147eb|\u001b[1;32mOK\u001b[0m  |       0B/s|c3/train-00000-of-00001.parquet\n",
      "\n",
      "Status Legend:\n",
      "(OK):download completed.\n",
      "\u001b[0;32mDownload completed successfully. Repo directory: /root/project/ZY/pytorch-transformer/transformers/MC\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!export HF_ENDPOINT=https://hf-mirror.com && ../hfd.sh clue/clue --dataset --include c3 --local-dir ./"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b3cb38",
   "metadata": {},
   "source": [
    "## import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76d169f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/pytorch/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForMultipleChoice,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DefaultDataCollator,\n",
    ")\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "os.environ[\"NCCL_P2P_DISABLE\"] = \"1\"\n",
    "os.environ[\"NCCL_IB_DISABLE\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73a4d21",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71bfdde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = load_dataset(\"./c3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9efa9a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'context': ['男：你今天晚上有时间吗?我们一起去看电影吧?', '女：你喜欢恐怖片和爱情片，但是我喜欢喜剧片，科幻片一般。所以……'],\n",
       " 'question': '女的最喜欢哪种电影?',\n",
       " 'choice': ['恐怖片', '爱情片', '喜剧片', '科幻片'],\n",
       " 'answer': '喜剧片'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e4d1143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'context', 'question', 'choice', 'answer'],\n",
       "    num_rows: 1625\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.pop(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4823e3ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'context', 'question', 'choice', 'answer'],\n",
       "        num_rows: 11869\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'context', 'question', 'choice', 'answer'],\n",
       "        num_rows: 3816\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61969dd",
   "metadata": {},
   "source": [
    "## Preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caa46c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"../chinese-macbert-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee4f0ea",
   "metadata": {},
   "source": [
    "we need to convert the data into a specific format.\n",
    "like this:\n",
    "\n",
    "|[CLS]|Context|[SEP]|Question|Choice A|[SEP]|\n",
    "\n",
    "|[CLS]|Context|[SEP]|Question|Choice B|[SEP]|\n",
    "\n",
    "|[CLS]|Context|[SEP]|Question|Choice C|[SEP]|\n",
    "\n",
    "|[CLS]|Context|[SEP]|Question|Choice D|[SEP]|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94d41fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(examples):\n",
    "    context = []\n",
    "    question_choices = []\n",
    "    labels = [] # to store the index of the correct answer\n",
    "    for idx in range(len(examples[\"context\"])):\n",
    "        ctx = \"\\n\".join(examples[\"context\"][idx])\n",
    "        question = examples[\"question\"][idx]\n",
    "        choices = examples[\"choice\"][idx]\n",
    "        for choice in choices:\n",
    "            context.append(ctx)\n",
    "            question_choices.append(f\"{question} {choice}\")\n",
    "        # some data may have no 4 choices\n",
    "        if len(choices) < 4:\n",
    "            for _ in range(4 - len(choices)):\n",
    "                context.append(ctx)\n",
    "                question_choices.append(f\"{question} 无\")\n",
    "        labels.append(choices.index(examples[\"answer\"][idx]))\n",
    "    tokenized_examples = tokenizer(\n",
    "        context,\n",
    "        question_choices,\n",
    "        truncation=\"only_first\", # truncate the context only\n",
    "        max_length=256,\n",
    "        padding=\"max_length\",\n",
    "    ) # Now the input_ids is 4000 * 256\n",
    "    tokenized_examples = {\n",
    "        k: [v[i : i + 4]\n",
    "        for i in range(0, len(v), 4)]\n",
    "        for k, v in tokenized_examples.items()  # group every 4 choices together\n",
    "    } # Now the input_ids is 1000 * 4 * 256\n",
    "    tokenized_examples[\"labels\"] = labels\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "854586f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 11869/11869 [00:14<00:00, 791.68 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = datasets.map(process, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1817f920",
   "metadata": {},
   "source": [
    "## Evaluate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "faa8eb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'evaluate' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/huggingface/evaluate.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc938d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\n",
    "    \"./evaluate/metrics/accuracy/accuracy.py\"\n",
    ")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    predictions, labels = pred\n",
    "    predictions = np.argmax(predictions, axis=-1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed34a589",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6018ad32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at ../chinese-macbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForMultipleChoice.from_pretrained(\"../chinese-macbert-base\")\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./models_mc\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=50,\n",
    "    load_best_model_at_end=True,\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9519f8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2226' max='2226' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2226/2226 08:35, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.006600</td>\n",
       "      <td>0.956741</td>\n",
       "      <td>0.594602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.996975</td>\n",
       "      <td>0.626834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.326800</td>\n",
       "      <td>1.347090</td>\n",
       "      <td>0.634958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2226, training_loss=0.7106486932715101, metrics={'train_runtime': 516.7814, 'train_samples_per_second': 68.901, 'train_steps_per_second': 4.307, 'total_flos': 1.873702246273229e+16, 'train_loss': 0.7106486932715101, 'epoch': 3.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656b8ae8",
   "metadata": {},
   "source": [
    "## Pipeline for Predition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e8bcb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class MultiChoicePipeline:\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = model.device\n",
    "    \n",
    "    def __call__(self, context, question, choices):\n",
    "        inputs = self.preprocess(context, question, choices)\n",
    "        logits = self.predict(inputs)\n",
    "        result = self.postprocess(logits, choices)\n",
    "        return result\n",
    "\n",
    "    def preprocess(self, context, question, choices):\n",
    "        ctx, qcs = [], []\n",
    "        for choice in choices:\n",
    "            ctx.append(context)\n",
    "            qcs.append(f\"{question} {choice}\")\n",
    "        \n",
    "        inputs = self.tokenizer(\n",
    "            ctx,\n",
    "            qcs,\n",
    "            truncation=\"only_first\",\n",
    "            max_length=256,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "    \n",
    "        return inputs\n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        inputs = {k: v.unsqueeze(0).to(self.device) for k, v in inputs.items()}\n",
    "        return self.model(**inputs).logits\n",
    "\n",
    "    def postprocess(self, logits, choices):\n",
    "        prediction = torch.argmax(logits, dim=1).item()\n",
    "        return choices[prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d0c064e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = MultiChoicePipeline(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93ed4b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'北京'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\n",
    "    \"小明在北京上班\",\n",
    "    \"小明在哪里上班？\",\n",
    "    [\"北京\", \"上海\", \"河北\", \"海南\", \"河北\", \"海南\"],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
